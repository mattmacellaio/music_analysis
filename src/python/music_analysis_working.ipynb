{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for each chunk: time each and match times where possible (streamline with APIs?)\n",
    "## - demucs separation - script will allow direct from file\n",
    "### - check for stereo: is stereo in output here?\n",
    "ffprobe rome.m4a 2>&1 | grep -A1 Duration\n",
    "### - split into two\n",
    "ffmpeg -i stereo.wav -map_channel 0.0.0 left.wav -map_channel 0.0.1 right.wav\n",
    "### - funnel each into demucs\n",
    "### - move from there up to analysis location\n",
    "## - load split files\n",
    "## - librosa: \n",
    "### - update color scheme\n",
    "### - circles: stack by lowest amp as total amp area, to highest amp as center\n",
    "### - possible to separate out by fundamental frequency?\n",
    "### - stereo effects? subtract wave from each channel, and difference = x value\n",
    "## - save frames > send directly to video\n",
    "## - make movie\n",
    "## - add audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa, sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from streamlit import caching\n",
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "\n",
    "#add white to colorlist for drums\n",
    "colorList = sns.color_palette('hsv', 12)\n",
    "colorList+=[(1,1,1)]\n",
    "#balance between low number for precision, high number for stability of pitch/amp calc\n",
    "hop_length = 2205\n",
    "#load all files, \n",
    "media_name = 'rome.m4a'\n",
    "filename = media_name.split('.')[0]\n",
    "print('loading')\n",
    "channels = {}\n",
    "\n",
    "for i, source in enumerate(['vocals','drums','other','bass']):\n",
    "    channels['filename'] = filename.split('.')[0]\n",
    "    channels[source] = {}\n",
    "#     channels[source]['combined'] = {}\n",
    "    channels[source][0] = {}\n",
    "    channels[source][1] = {}\n",
    "#     channels[source]['combined']['audio'], sr = librosa.load(f\"demucs/separated/demucs/{filename}/{source}/{source}.wav\", sr=None)\n",
    "#         split here?\n",
    "    os.system(f\"ffmpeg -i {source}/{source}.wav -map_channel 0.0.0 {source}/left.wav -map_channel 0.0.1 {source}/right.wav\")\n",
    "    channels[source][0]['audio'], sr = librosa.load(f\"demucs/separated/demucs/{filename}/{source}/left.wav\", sr=None)\n",
    "    channels[source][1]['audio'], sr = librosa.load(f\"demucs/separated/demucs/{filename}/{source}/right.wav\", sr=None)\n",
    "#     channels[source]['stft'] = librosa.stft(channels[source]['audio'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = range(len(channels[channel]['audio']))\n",
    "# t = librosa.frames_to_time(frames[0:1000*512])\n",
    "# for channel in channels.keys():\n",
    "#     plt.plot(t,np.abs(channels[channel]['audio'][0:1000*512]))\n",
    "# plt.legend(channels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testright = channels['other'][1]['audio']*-1+channels['other'][0]['audio']\n",
    "testleft = channels['other'][0]['audio']*-1+channels['other'][1]['audio']\n",
    "IPython.display.Audio(data=channels['other'][0]['audio'], rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=channels['other'][0]['audio'], rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samprange = range(0, sr*25)\n",
    "plt.plot(samprange, \n",
    "#          channels['other'][0]['audio'][samprange]-channels['other'][1]['audio'][samprange], \n",
    "#          channels['other'][1]['audio'][samprange]-channels['other'][0]['audio'][samprange], \n",
    "         channels['other'][0]['audio'][samprange], \n",
    "         channels['other'][1]['audio'][samprange])\n",
    "plt.legend(['l-r','r-l','left','right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, source in enumerate([k for k in channels.keys() if k not in ['filename','drums']]):\n",
    "    print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in channels.keys():\n",
    "    if source != 'filename':\n",
    "        for channel in [0,1]:\n",
    "            if source != 'drums':\n",
    "                #pitch is defaulting to F across the board on Rome. is that the case for OW too?\n",
    "                chromagram = librosa.feature.chroma_stft(channels[source][channel]['audio'], sr=sr, hop_length=hop_length)\n",
    "                channels[source][channel]['pitch'] = chromagram\n",
    "            else:\n",
    "                channels[source][channel]['pitch'] = np.repeat(12, int(np.floor(len(channels[source][channel]['audio'])/hop_length)))\n",
    "                \n",
    "            channels[source][channel]['amp'] = np.array([np.mean(abs(channels[source][channel]['audio'][(s*hop_length):(s*hop_length+hop_length)])) \n",
    "                                            for s in range(int(np.floor(len(channels[source][channel]['audio'])/hop_length))-1)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "def plotimages(s, dataDict, colorList):\n",
    "    # take maximum-amplitude pitch for the sample, normalize sample ampl by maximum ampl (or by \"other\"?)\n",
    "    # for now, use pitch from channel with larger amp. \n",
    "    # how to handle two-channel bass better? revert back to circles?\n",
    "    channel = np.argmax([abs(dataDict['bass'][0]['amp'][s]),abs(dataDict['bass'][1]['amp'][s])])\n",
    "    bgcolor = [c*0.5*(abs(dataDict['bass'][channel]['amp'][s])/\n",
    "                      abs(max(dataDict['bass'][channel]['amp']))) for c in \n",
    "               colorList[np.argmax(dataDict['bass'][channel]['pitch'][:,s])]] \n",
    "                                   \n",
    "    plt.rcParams['axes.facecolor'] = bgcolor\n",
    "    plt.rcParams['savefig.facecolor'] = bgcolor\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    for channel in [0,1]:\n",
    "        #drums\n",
    "        plt.plot(1+channel,1.5, 'o',\n",
    "                 markerfacecolor = colorList[dataDict['drums'][channel]['pitch'][s]], \n",
    "                 markeredgecolor = colorList[dataDict['drums'][channel]['pitch'][s]], \n",
    "                 markersize = dataDict['drums'][channel]['amp'][s]*100)\n",
    "\n",
    "        #grab pitches in reverse order of strength, only using top few\n",
    "        topchr = np.argsort(dataDict['vocals'][channel]['pitch'][:,s])\n",
    "        for pitch_rank in range(-1, 1):\n",
    "            plt.plot(.5+channel*2,0.75, 'o',\n",
    "                     markerfacecolor = colorList[topchr[pitch_rank]], \n",
    "                     markeredgecolor = colorList[topchr[pitch_rank]],\n",
    "                     markersize = 250*dataDict['vocals'][channel]['amp'][s]*sum(dataDict['vocals'][channel]['pitch'][topchr[range(pitch_rank,1)],s]))\n",
    "\n",
    "        topchr = np.argsort(dataDict['other'][channel]['pitch'][:,s])\n",
    "        for pitch_rank in range(-1, 1):\n",
    "            plt.plot(0.5+channel*2,2.25, 'o',\n",
    "                     markerfacecolor = colorList[topchr[pitch_rank]], \n",
    "                     markeredgecolor = colorList[topchr[pitch_rank]],\n",
    "                     markersize = 250*dataDict['other'][channel]['amp'][s]*sum(dataDict['other'][channel]['pitch'][topchr[range(pitch_rank,1)],s]))\n",
    "    plt.xlim(0,3)\n",
    "    plt.ylim(0,3)\n",
    "    plt.axis('off')\n",
    "    digits = len(str(len(dataDict['vocals'][0]['amp'])))\n",
    "    plt.savefig(f\"{dataDict['filename']}_frames2/{s:0{digits}d}.png\", \n",
    "                facecolor=ax.get_facecolor(), edgecolor='none')\n",
    "    plt.close()\n",
    "#     canvas = plt.gca().figure.canvas\n",
    "#     canvas.draw()\n",
    "#     data = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8)\n",
    "#     image = data.reshape(canvas.get_width_height()[::-1] + (3,))\n",
    "# #     #alternative?\n",
    "# #      # redraw the canvas\n",
    "#     fig.canvas.draw()\n",
    "#     # convert canvas to image\n",
    "#     img = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "#     img  = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "# # then outside\n",
    "#     # img is rgb, convert to opencv's default bgr\n",
    "# #     img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "# #     cv2.imshow(\"plot\",img)\n",
    "\n",
    "#     return [img, image]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = len(str(len(channels['vocals'][0]['amp'])))\n",
    "\n",
    "startt = datetime.now()\n",
    "if f\"{filename}_frames2\" not in os.listdir():\n",
    "    os.mkdir(f\"{filename}_frames2\")\n",
    "\n",
    "start_frame = len(sorted(os.listdir(f'{filename}_frames2/')))-1\n",
    "\n",
    "while start_frame < 2000:\n",
    "    print(f\"{start_frame}\")\n",
    "    for i in tqdm(range(start_frame, min(start_frame+1000, len(channels['vocals'][0]['amp'])))):\n",
    "        plotimages(i, dataDict = channels, colorList = colorList)\n",
    "\n",
    "\n",
    "    image = cv2.imread(f\"{filename}_frames/{os.listdir(f'{filename}_frames/')[0]}\")\n",
    "    height, width, layers = image.shape\n",
    "    size = (width,height)\n",
    "\n",
    "    if f\"{filename}.avi\" in os.listdir():\n",
    "        os.remove(f\"{filename}.avi\")\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    os.system(f\"rm -f {filename}.avi\")\n",
    "    video = cv2.VideoWriter(f\"{filename}.avi\", \n",
    "                            fourcc, \n",
    "                            sr/hop_length, \n",
    "                            size)\n",
    "    for i in tqdm(range(len(sorted(os.listdir(f'{filename}_frames'))))):\n",
    "        image = cv2.imread(f'{filename}_frames/{i:0{digits}d}.png')\n",
    "        video.write(image.astype('uint8'))\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(datetime.now()-startt)\n",
    "    if f\"{filename}_waud.avi\" in os.listdir():\n",
    "        os.remove(f\"{filename}_waud.avi\")\n",
    "    os.system(f\"ffmpeg -i {filename}.avi -i {media_name} -map 0 -map 1:a -c:v copy -shortest {filename}_waud.avi\")\n",
    "\n",
    "    caching.clear_cache()\n",
    "    \n",
    "#     print(datetime.now()-startt)\n",
    "#     clip_1 = VideoFileClip(f\"{filename}.avi\")\n",
    "#     clip_2 = VideoFileClip(f\"{filename}_tmp.avi\")\n",
    "#     final_clip = concatenate_videoclips([clip_1,clip_2])\n",
    "#     final_clip.write_videofile(f\"{filename}.avi\")\n",
    "# this downsamples the video, it seems? ugh.\n",
    "# os.system(\"ffmpeg -i rome.avi -i rome_waud.avi -filter_complex '[0:v] [0:a:0] [1:v] [1:a:0] concat=n=2:v=1:a=1 [v] [a]' -map '[v]' -map '[a]' rome_concat.avi\")\n",
    "\n",
    "    start_frame = len(sorted(os.listdir(f'{filename}_frames/')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"ffmpeg -i {filename}.avi -i {media_name} -map 0 -map 1:a -c:v copy -shortest {filename}_waud.avi\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rome'\n",
    "media_name = 'rome.m4a'\n",
    "f\"ffmpeg -i {filename}.avi -i {media_name} -map 0 -map 1:a -c:v copy -shortest {filename}_waud.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# for img in sorted(os.listdir(image_folder)):\n",
    "#     if img.endswith(\".jpg\"):\n",
    "#         for i in range(100):\n",
    "#             image_files += [f\"{image_folder}/{img}\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamlit import caching\n",
    "caching.clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "# y, srdown = librosa.load(f\"catempire_oscarwilde.mp3\", sr = 4300)\n",
    "sf.write('catempire_oscarwilde_47.wav', ow_47, sr)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import moviepy\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "from moviepy.audio.AudioClip import CompositeAudioClip\n",
    "import moviepy.video.io.ImageSequenceClip\n",
    "from datetime import datetime\n",
    "image_folder='catempire_oscarwilde_frames/'\n",
    "srdown = sr/hop_length\n",
    "image_files = []\n",
    "\n",
    "for img in sorted(os.listdir(image_folder)):\n",
    "    if img.endswith(\".jpg\"):\n",
    "        for i in range(100):\n",
    "            image_files += [f\"{image_folder}/{img}\"]\n",
    "startt = datetime.now()\n",
    "clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=srdown) #pass in list of images instead?\n",
    "print(datetime.now()-startt)\n",
    "# audioclip = AudioFileClip(\"catempire_oscarwilde_47.wav\", fps = sr)\n",
    "\n",
    "# # new_audioclip = CompositeAudioClip([audioclip])\n",
    "# clip.audio = audioclip\n",
    "clip.write_videofile(\"oscarwilde100_2.mp4\", fps = srdown, threads=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ow_47 = librosa.load('catempire_oscarwilde.mp3', duration=47)\n",
    "IPython.display.Audio(data=ow_47, rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromagram = librosa.feature.chroma_stft(channels['vocals']['audio'], sr=sr, hop_length=512)\n",
    "chromagram.shape\n",
    "librosa.display.specshow(chromagram[:,0:1000], x_axis='time', y_axis='chroma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromagram = librosa.feature.chroma_stft(channels['other']['audio'], sr=sr, hop_length=512)\n",
    "librosa.display.specshow(chromagram[:,0:1000], x_axis='time', y_axis='chroma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=channels[channel]['audio'], rate=sr/1.5, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('catempire_oscarwilde.mp3')\n",
    "D = librosa.stft(y)\n",
    "\n",
    "# Pre-compute a global reference power from the input spectrum\n",
    "rp = np.max(np.abs(D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "D_harmonic, D_percussive = librosa.decompose.hpss(D, kernel_size = [1000,1000])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Full spectrogram')\n",
    "ax[0].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "ax[1].set(title='Harmonic spectrogram')\n",
    "ax[1].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='Percussive spectrogram')\n",
    "fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_harmonic, D_percussive = librosa.decompose.hpss(D, kernel_size = [15,1000])\n",
    "\n",
    "# IPython.display.Audio(data=librosa.istft(D_harmonic), rate=sr, autoplay = True)\n",
    "# IPython.display.Audio(data=librosa.istft(D_percussive), rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yfb, sr = librosa.load('catempire_oscarwilde/drums.wav')\n",
    "# Dfb = librosa.stft(yfb)\n",
    "\n",
    "# Pre-compute a global reference power from the input spectrum\n",
    "rpfb = np.max(np.abs(Dfb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "rp = np.max(np.abs(D))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Full spectrogram')\n",
    "ax[0].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(Dfb), ref=rpfb),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "ax[1].set(title='Harmonic spectrogram')\n",
    "ax[1].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='Percussive spectrogram')\n",
    "fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "load_dur = 90\n",
    "y, sr = librosa.load('catempire_oscarwilde.mp3', duration = load_dur)\n",
    "chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
    "rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "D = librosa.stft(y)\n",
    "rf = np.max(np.abs(D))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "\n",
    "fig, ax = plt.subplots(5,1)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(D, ref=rp),y_axis='log', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Spectogram')\n",
    "\n",
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis)#Plotting the Spectral Centroid along the waveform\n",
    "spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "\n",
    "frames = range(len(spec_cent))\n",
    "t = librosa.frames_to_time(frames)\n",
    "# librosa.display.waveplot(y, sr=sr, alpha=0.4)\n",
    "ax[1].plot(t, spec_cent, color='r')\n",
    "ax[1].set(title='spectral centroid')\n",
    "ax[1].set_xlim([0,load_dur])\n",
    "\n",
    "mfccs = sklearn.preprocessing.scale(mfcc, axis=1)\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='MFCC')\n",
    "\n",
    "hop_length = 28\n",
    "chromagram = librosa.feature.chroma_stft(y, sr=sr, hop_length=hop_length)\n",
    "librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', ax = ax[3])\n",
    "ax[3].set(title = 'chromagram')\n",
    "\n",
    "ax[4].plot(spec_bw, color='r')\n",
    "ax[4].set(title='spectral bandwidth')\n",
    "ax[4].set_xlim([0,load_dur])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y, rate=sr/1.5, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_offset, sr = librosa.load('catempire_oscarwilde.mp3', duration=60, offset = 60)\n",
    "D = librosa.stft(y_offset)\n",
    "rp = np.max(np.abs(D))\n",
    "\n",
    "#higher percussive kernel_size better for isolating\n",
    "# y_h1515, y_p1515 = librosa.effects.hpss(y_offset, kernel_size = [15,1000]) \n",
    "# D_H1515, D_P1515 = librosa.decompose.hpss(D, kernel_size = [15,1000])\n",
    "# IPython.display.Audio(data=y_h1515, rate=sr, autoplay = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h155, y_p155 = librosa.effects.hpss(y, kernel_size = [15,5])\n",
    "D_H155, D_P155 = librosa.decompose.hpss(D, kernel_size = [15,5])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, sharex=True, sharey=True)\n",
    "dp = {}\n",
    "dh = {}\n",
    "for i,ks in enumerate([5,10,100,1000]):\n",
    "    dh[i], dp[i] = librosa.decompose.hpss(D, kernel_size = [15,ks])\n",
    "\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(dp[i][:, 0:250]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[i])\n",
    "    ax[i].set(title=f'{ks}')\n",
    "\n",
    "# IPython.display.Audio(data=y_p1515[0:sr*10], rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = datetime.datetime.now()/\n",
    "rp = np.max(np.abs(D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=2, sharex=True, sharey=True)\n",
    "dp = {}\n",
    "dh = {}\n",
    "yp = {}\n",
    "yh = {}\n",
    "start = datetime.datetime.now()\n",
    "for i,ks in enumerate([5,10,100,1000]):\n",
    "    dh[i], dp[i] = librosa.decompose.hpss(D, kernel_size = [ks,1000])\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(dh[i][:, 0:250]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[i,0])\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(dp[i][:, 0:250]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[i,1])\n",
    "    ax[i,0].set(title=f'{ks}, harmonic')\n",
    "    ax[i,1].set(title=f'{ks}, Percussive')\n",
    "    yh[i] = librosa.istft(dh[i])\n",
    "    yp[i] = librosa.istft(dp[i])\n",
    "    print(datetime.datetime.now()-start)\n",
    "\n",
    "# IPython.display.Audio(data=yp[0], rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=2, sharex=True, sharey=True)\n",
    "dp3 = {}\n",
    "dh3 = {}\n",
    "yp3 = {}\n",
    "yh3 = {}\n",
    "start = datetime.datetime.now()\n",
    "for i,ks in enumerate([5,10,100,1000]):\n",
    "    dh3[i], dp3[i] = librosa.decompose.hpss(D, kernel_size = [ks,31])\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(dh3[i][:, 0:250]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[i,0])\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(dp3[i][:, 0:250]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[i,1])\n",
    "    ax[i,0].set(title=f'{ks}, harmonic')\n",
    "    ax[i,1].set(title=f'{ks}, Percussive')\n",
    "    yh3[i] = librosa.istft(dh3[i])\n",
    "    yp3[i] = librosa.istft(dp3[i])\n",
    "    print(datetime.datetime.now()-start)\n",
    "\n",
    "# IPython.display.Audio(data=yp[0], rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=yp[1], rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb, srb = librosa.load(librosa.ex('vibeace'), duration = 60)\n",
    "Db = librosa.stft(yb)\n",
    "rpb = np.max(np.abs(Db))\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True)\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(Db), ref=rpb),\n",
    "                         y_axis='log', x_axis='time', ax=ax)\n",
    "IPython.display.Audio(data=yb, rate=srb, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute separations for a few different margins and compare the results below\n",
    "# D_harmonic2, D_percussive2 = librosa.decompose.hpss(D, margin=2)\n",
    "# D_harmonic4, D_percussive4 = librosa.decompose.hpss(D, margin=4)\n",
    "# D_harmonic8, D_percussive8 = librosa.decompose.hpss(D, margin=8)\n",
    "# D_harmonic16, D_percussive16 = librosa.decompose.hpss(D, margin=16)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, sharex=True, sharey=True)\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic2), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0])\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic4), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic8), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2])\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic16), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_harmonic2, y_percussive2 = librosa.effects.hpss(y, margin=2)\n",
    "IPython.display.Audio(data=y_harmonic2, rate=sr)\n",
    "\n",
    "y_harmonic4, y_percussive4 = librosa.effects.hpss(y, margin=4)\n",
    "IPython.display.Audio(data=y_harmonic4, rate=sr)\n",
    "\n",
    "y_harmonic8, y_percussive8 = librosa.effects.hpss(y, margin=8)\n",
    "IPython.display.Audio(data=y_harmonic8, rate=sr)\n",
    "\n",
    "y_harmonic16, y_percussive16 = librosa.effects.hpss(y, margin=16)\n",
    "IPython.display.Audio(data=y_harmonic16, rate=sr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y_h, rate=sr, autoplay = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about something more advanced?  Let's decompose a spectrogram with NMF, and then resynthesize an individual component\n",
    "D = librosa.stft(y)\n",
    "rp = np.max(np.abs(D))\n",
    "\n",
    "# Separate the magnitude and phase\n",
    "S, phase = librosa.magphase(D_harmonic)\n",
    "\n",
    "# Decompose by nmf\n",
    "components, activations = librosa.decompose.decompose(S, n_components=4, sort=True)\n",
    "# Resynthesize.  How about we isolate components?\n",
    "fig, ax = plt.subplots(nrows=len(activations), sharex=True, sharey=True)\n",
    "\n",
    "y_k = list(range(len(activations)))\n",
    "for k in range(len(activations)):\n",
    "    \n",
    "    # Reconstruct a spectrogram by the outer product of component k and its activation\n",
    "    D_k = np.multiply.outer(components[:, k], activations[k])\n",
    "\n",
    "    # invert the stft after putting the phase back in\n",
    "    y_k[k] = librosa.istft(D_k * phase)\n",
    "\n",
    "    # And playback\n",
    "    print('Component #{}'.format(k))\n",
    "\n",
    "    IPython.display.Audio(data=y_k[k], rate=sr)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_k), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[k])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y_k[2], rate=sr, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y, rate=sr, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
