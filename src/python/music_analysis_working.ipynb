{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for each chunk: time each and match times where possible (streamline with APIs?)\n",
    "## - demucs separation - script will allow direct from file\n",
    "### - check for stereo: is stereo in output here?\n",
    "ffprobe rome.m4a 2>&1 | grep -A1 Duration\n",
    "### - split into two\n",
    "ffmpeg -i stereo.wav -map_channel 0.0.0 left.wav -map_channel 0.0.1 right.wav\n",
    "### - funnel each into demucs\n",
    "### - move from there up to analysis location\n",
    "## - load split files\n",
    "## - librosa: \n",
    "### - update color scheme\n",
    "### - circles: stack by lowest amp as total amp area, to highest amp as center\n",
    "### - possible to separate out by fundamental frequency?\n",
    "### - stereo effects? subtract wave from each channel, and difference = x value\n",
    "## - save frames > send directly to video\n",
    "## - make movie\n",
    "## - add audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa, sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "from datetime import datetime\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from streamlit import caching\n",
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "\n",
    "#add white to colorlist for drums\n",
    "colorList = sns.color_palette('hsv', 12)\n",
    "colorList+=[(1,1,1)]\n",
    "#balance between low number for precision, high number for stability of pitch/amp calc\n",
    "hop_length = 2205\n",
    "#load all files, \n",
    "media_name = 'raw_music/aintnosunshine.mp3'\n",
    "filename = media_name.split('.')[0].split('/')[1]\n",
    "print('loading')\n",
    "channels = {}\n",
    "\n",
    "# #generate separated files with demucs, move to their own folders\n",
    "# if not(os.path.isdir(f\"demucs/separated/demucs/{filename}\")):\n",
    "#     os.system(f'cd ../../ python -m demucs.separate -d cpu --dl {media_name}')\n",
    "\n",
    "# if not(os.path.isdir(f\"demucs/separated/demucs/{filename}/vocals\")):\n",
    "#     for file in os.listdir(f'demucs/separated/demucs/{filename}'):\n",
    "#         os.mkdir(f\"demucs/separated/demucs/{filename}/{file.split('.')[0]}\")\n",
    "#         os.system(f\"mv demucs/separated/demucs/{filename}/{file} demucs/separated/demucs/{filename}/{file.split('.')[0]}\")\n",
    "\n",
    "#load\n",
    "for i, source in enumerate(['vocals','drums','other','bass']):\n",
    "    print(source)\n",
    "    channels['filename'] = filename.split('.')[0]\n",
    "    channels[source] = {}\n",
    "#     channels[source]['combined'] = {}\n",
    "    channels[source][0] = {}\n",
    "    channels[source][1] = {}\n",
    "    if 'left.wav' not in os.listdir(f\"demucs/separated/demucs/{filename}/{source}\"):\n",
    "#     split to left/right (how to automate if there is no stereo?)\n",
    "        os.system(f\"ffmpeg -i {source}/{source}.wav -map_channel 0.0.0 {source}/left.wav -map_channel 0.0.1 {source}/right.wav\")\n",
    "\n",
    "#     channels[source]['combined']['audio'], sr = librosa.load(f\"demucs/separated/demucs/{filename}/{source}/{source}.wav\", sr=None)\n",
    "    channels[source][0]['audio'], sr = librosa.load(f\"demucs/separated/demucs/{filename}/{source}/left.wav\", sr=None)\n",
    "    channels[source][1]['audio'], sr = librosa.load(f\"demucs/separated/demucs/{filename}/{source}/right.wav\", sr=None)\n",
    "#     channels[source]['stft'] = librosa.stft(channels[source]['audio'])\n",
    "\n",
    "# generate pitch and amplitude\n",
    "print('pitch and amplitude')\n",
    "for source in channels.keys():\n",
    "    if source != 'filename':\n",
    "        for channel in [0,1]:\n",
    "            if source != 'drums':\n",
    "                #pitch is defaulting to F across the board on Rome. is that the case for OW too?\n",
    "                chromagram = librosa.feature.chroma_stft(channels[source][channel]['audio'], sr=sr, hop_length=hop_length)\n",
    "                channels[source][channel]['pitch'] = chromagram\n",
    "            else:\n",
    "                channels[source][channel]['pitch'] = np.repeat(12, int(np.floor(len(channels[source][channel]['audio'])/hop_length)))\n",
    "                \n",
    "            channels[source][channel]['amp'] = np.array([np.mean(abs(channels[source][channel]['audio'][(s*hop_length):(s*hop_length+hop_length)])) \n",
    "                                            for s in range(int(np.floor(len(channels[source][channel]['audio'])/hop_length))-1)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "mpatches.Rectangle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "def plotimages(s, dataDict, colorList):\n",
    "    # take maximum-amplitude pitch for the sample, normalize sample ampl by maximum ampl (or by \"other\"?)\n",
    "    # for now, use pitch from channel with larger amp. \n",
    "    # how to handle two-channel bass better? revert back to circles?\n",
    "\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    channel = np.argmax([abs(dataDict['bass'][0]['amp'][s]),abs(dataDict['bass'][1]['amp'][s])])\n",
    "    bgcolor = [c*0.5*(abs(dataDict['bass'][channel]['amp'][s])/\n",
    "                      abs(max(dataDict['bass'][channel]['amp']))) for c in \n",
    "               colorList[np.argmax(dataDict['bass'][channel]['pitch'][:,s])]] \n",
    "\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "                                   \n",
    "    # add a rectangle\n",
    "    rect = mpatches.Rectangle([0,0], 3, 3, ec=\"none\", facecolor = bgcolor)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    for channel in [0,1]:\n",
    "        #drums\n",
    "        plt.plot(1+channel,1.5, 'o',\n",
    "                 markerfacecolor = colorList[dataDict['drums'][channel]['pitch'][s]], \n",
    "                 markeredgecolor = colorList[dataDict['drums'][channel]['pitch'][s]], \n",
    "                 markersize = dataDict['drums'][channel]['amp'][s]*100)\n",
    "\n",
    "        #grab pitches in reverse order of strength, only using top few\n",
    "        topchr = np.argsort(dataDict['vocals'][channel]['pitch'][:,s])\n",
    "        for pitch_rank in range(-1, 1):\n",
    "            plt.plot(.5+channel*2,0.75, 'o',\n",
    "                     markerfacecolor = colorList[topchr[pitch_rank]], \n",
    "                     markeredgecolor = colorList[topchr[pitch_rank]],\n",
    "                     markersize = 250*dataDict['vocals'][channel]['amp'][s]*\n",
    "                     sum(dataDict['vocals'][channel]['pitch'][topchr[range(pitch_rank,1)],s]))\n",
    "\n",
    "        topchr = np.argsort(dataDict['other'][channel]['pitch'][:,s])\n",
    "        for pitch_rank in range(-1, 1):\n",
    "            plt.plot(0.5+channel*2,2.25, 'o',\n",
    "                     markerfacecolor = colorList[topchr[pitch_rank]], \n",
    "                     markeredgecolor = colorList[topchr[pitch_rank]],\n",
    "                     markersize = 250*dataDict['other'][channel]['amp'][s]*sum(dataDict['other'][channel]['pitch'][topchr[range(pitch_rank,1)],s]))\n",
    "    plt.xlim(0,3)\n",
    "    plt.ylim(0,3)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # redraw the canvas\n",
    "    fig.canvas.draw()\n",
    "\n",
    "#     # convert canvas to image\n",
    "    img = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8,\n",
    "            sep='')\n",
    "    img  = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "#     # img is rgb, convert to opencv's default bgr\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "    plt.close(fig)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = len(str(len(channels['vocals'][0]['amp'])))\n",
    "\n",
    "startt = datetime.now()\n",
    "if f\"{filename}_frames\" not in os.listdir():\n",
    "    os.mkdir(f\"{filename}_frames\")\n",
    "\n",
    "start_frame = len(sorted(os.listdir(f'{filename}_frames/')))\n",
    "size = (1152,864)\n",
    "\n",
    "if f\"{filename}.avi\" in os.listdir():\n",
    "    os.remove(f\"{filename}.avi\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "os.system(f\"rm -f {filename}.avi\")\n",
    "video = cv2.VideoWriter(f\"{filename}cv2.avi\", \n",
    "                        fourcc, \n",
    "                        sr/hop_length, \n",
    "                        size)\n",
    "\n",
    "for i in tqdm(range(500,len(channels['vocals'][0]['amp']))):\n",
    "    image = plotimages(i, dataDict = channels, colorList = colorList)\n",
    "    video.write(image.astype('uint8'))\n",
    "\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(datetime.now()-startt)\n",
    "if f\"{filename}_waud.avi\" in os.listdir():\n",
    "    os.remove(f\"{filename}_waud.avi\")\n",
    "os.system(f\"ffmpeg -i {filename}cv2.avi -i {media_name} -map 0 -map 1:a -c:v copy -shortest {filename}_waud.avi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA, PCA\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "ica = FastICA(n_components=3)\n",
    "X = np.array([channels['other'][0]['audio'].reshape(-1,1), channels['other'][1]['audio'].reshape(-1,1)])[:,:,0].T\n",
    "\n",
    "S_ = ica.fit_transform(X)  # Reconstruct signals\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# # X.shape\n",
    "# H = pca.fit_transform(X) \n",
    "plt.subplot(221)\n",
    "plt.plot(S_[sr*11:sr*20,0])\n",
    "plt.subplot(222)\n",
    "plt.plot(S_[sr*11:sr*20,0])\n",
    "plt.subplot(223)\n",
    "D = librosa.stft(S_[sr*11:sr*20,0])\n",
    "rp = np.max(np.abs(D))\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=rp),\n",
    "                         y_axis='log', x_axis='time')\n",
    "plt.subplot(224)\n",
    "\n",
    "D = librosa.stft(S_[sr*11:sr*20,1])\n",
    "rp = np.max(np.abs(D))\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=rp),\n",
    "                         y_axis='log', x_axis='time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "librosa.display.specshow(channels['other'][channel]['pitch'][:,int(channels['other'][channel]['pitch'].shape[1]/5):int(channels['other'][channel]['pitch'].shape[1]/5)*2], \n",
    "                         x_axis='time', y_axis='chroma', ax = ax[0])\n",
    "# D = librosa.stft(channels['other'][channel]['audio'])\n",
    "# rp = np.max(np.abs(D))\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D[:,int(D.shape[1]/5):int(D.shape[1]/5)*2]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import moviepy\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "from moviepy.audio.AudioClip import CompositeAudioClip\n",
    "import moviepy.video.io.ImageSequenceClip\n",
    "from datetime import datetime\n",
    "image_folder='catempire_oscarwilde_frames/'\n",
    "srdown = sr/hop_length\n",
    "image_files = []\n",
    "\n",
    "for img in sorted(os.listdir(image_folder)):\n",
    "    if img.endswith(\".jpg\"):\n",
    "        for i in range(100):\n",
    "            image_files += [f\"{image_folder}/{img}\"]\n",
    "startt = datetime.now()\n",
    "clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=srdown) #pass in list of images instead?\n",
    "print(datetime.now()-startt)\n",
    "# audioclip = AudioFileClip(\"catempire_oscarwilde_47.wav\", fps = sr)\n",
    "\n",
    "# # new_audioclip = CompositeAudioClip([audioclip])\n",
    "# clip.audio = audioclip\n",
    "clip.write_videofile(\"oscarwilde100_2.mp4\", fps = srdown, threads=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ow_47 = librosa.load('catempire_oscarwilde.mp3', duration=47)\n",
    "IPython.display.Audio(data=ow_47, rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromagram = librosa.feature.chroma_stft(channels['vocals']['audio'], sr=sr, hop_length=512)\n",
    "chromagram.shape\n",
    "librosa.display.specshow(chromagram[:,0:1000], x_axis='time', y_axis='chroma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromagram = librosa.feature.chroma_stft(channels['other']['audio'], sr=sr, hop_length=512)\n",
    "librosa.display.specshow(chromagram[:,0:1000], x_axis='time', y_axis='chroma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=channels[channel]['audio'], rate=sr/1.5, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('catempire_oscarwilde.mp3')\n",
    "D = librosa.stft(y)\n",
    "\n",
    "# Pre-compute a global reference power from the input spectrum\n",
    "rp = np.max(np.abs(D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "D_harmonic, D_percussive = librosa.decompose.hpss(D, kernel_size = [1000,1000])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Full spectrogram')\n",
    "ax[0].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "ax[1].set(title='Harmonic spectrogram')\n",
    "ax[1].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='Percussive spectrogram')\n",
    "fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_harmonic, D_percussive = librosa.decompose.hpss(D, kernel_size = [15,1000])\n",
    "\n",
    "# IPython.display.Audio(data=librosa.istft(D_harmonic), rate=sr, autoplay = True)\n",
    "# IPython.display.Audio(data=librosa.istft(D_percussive), rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yfb, sr = librosa.load('catempire_oscarwilde/drums.wav')\n",
    "# Dfb = librosa.stft(yfb)\n",
    "\n",
    "# Pre-compute a global reference power from the input spectrum\n",
    "rpfb = np.max(np.abs(Dfb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "rp = np.max(np.abs(D))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Full spectrogram')\n",
    "ax[0].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(Dfb), ref=rpfb),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "ax[1].set(title='Harmonic spectrogram')\n",
    "ax[1].label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_percussive), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='Percussive spectrogram')\n",
    "fig.colorbar(img, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "load_dur = 90\n",
    "y, sr = librosa.load('catempire_oscarwilde.mp3', duration = load_dur)\n",
    "chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
    "rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "D = librosa.stft(y)\n",
    "rf = np.max(np.abs(D))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "\n",
    "fig, ax = plt.subplots(5,1)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(D, ref=rp),y_axis='log', x_axis='time', ax=ax[0])\n",
    "ax[0].set(title='Spectogram')\n",
    "\n",
    "def normalize(x, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x, axis=axis)#Plotting the Spectral Centroid along the waveform\n",
    "spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "\n",
    "frames = range(len(spec_cent))\n",
    "t = librosa.frames_to_time(frames)\n",
    "# librosa.display.waveplot(y, sr=sr, alpha=0.4)\n",
    "ax[1].plot(t, spec_cent, color='r')\n",
    "ax[1].set(title='spectral centroid')\n",
    "ax[1].set_xlim([0,load_dur])\n",
    "\n",
    "mfccs = sklearn.preprocessing.scale(mfcc, axis=1)\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time', ax=ax[2])\n",
    "ax[2].set(title='MFCC')\n",
    "\n",
    "hop_length = 28\n",
    "chromagram = librosa.feature.chroma_stft(y, sr=sr, hop_length=hop_length)\n",
    "librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', ax = ax[3])\n",
    "ax[3].set(title = 'chromagram')\n",
    "\n",
    "ax[4].plot(spec_bw, color='r')\n",
    "ax[4].set(title='spectral bandwidth')\n",
    "ax[4].set_xlim([0,load_dur])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y, rate=sr/1.5, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_offset, sr = librosa.load('catempire_oscarwilde.mp3', duration=60, offset = 60)\n",
    "D = librosa.stft(y_offset)\n",
    "rp = np.max(np.abs(D))\n",
    "\n",
    "#higher percussive kernel_size better for isolating\n",
    "# y_h1515, y_p1515 = librosa.effects.hpss(y_offset, kernel_size = [15,1000]) \n",
    "# D_H1515, D_P1515 = librosa.decompose.hpss(D, kernel_size = [15,1000])\n",
    "# IPython.display.Audio(data=y_h1515, rate=sr, autoplay = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h155, y_p155 = librosa.effects.hpss(y, kernel_size = [15,5])\n",
    "D_H155, D_P155 = librosa.decompose.hpss(D, kernel_size = [15,5])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, sharex=True, sharey=True)\n",
    "dp = {}\n",
    "dh = {}\n",
    "for i,ks in enumerate([5,10,100,1000]):\n",
    "    dh[i], dp[i] = librosa.decompose.hpss(D, kernel_size = [15,ks])\n",
    "\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(dp[i][:, 0:250]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[i])\n",
    "    ax[i].set(title=f'{ks}')\n",
    "\n",
    "# IPython.display.Audio(data=y_p1515[0:sr*10], rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = datetime.datetime.now()/\n",
    "rp = np.max(np.abs(D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=2, sharex=True, sharey=True)\n",
    "dp = {}\n",
    "dh = {}\n",
    "yp = {}\n",
    "yh = {}\n",
    "start = datetime.datetime.now()\n",
    "for i,ks in enumerate([5,10,100,1000]):\n",
    "    dh[i], dp[i] = librosa.decompose.hpss(D, kernel_size = [ks,1000])\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(dh[i][:, 0:250]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[i,0])\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(dp[i][:, 0:250]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[i,1])\n",
    "    ax[i,0].set(title=f'{ks}, harmonic')\n",
    "    ax[i,1].set(title=f'{ks}, Percussive')\n",
    "    yh[i] = librosa.istft(dh[i])\n",
    "    yp[i] = librosa.istft(dp[i])\n",
    "    print(datetime.datetime.now()-start)\n",
    "\n",
    "# IPython.display.Audio(data=yp[0], rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=2, sharex=True, sharey=True)\n",
    "dp3 = {}\n",
    "dh3 = {}\n",
    "yp3 = {}\n",
    "yh3 = {}\n",
    "start = datetime.datetime.now()\n",
    "for i,ks in enumerate([5,10,100,1000]):\n",
    "    dh3[i], dp3[i] = librosa.decompose.hpss(D, kernel_size = [ks,31])\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(dh3[i][:, 0:250]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[i,0])\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(dp3[i][:, 0:250]), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[i,1])\n",
    "    ax[i,0].set(title=f'{ks}, harmonic')\n",
    "    ax[i,1].set(title=f'{ks}, Percussive')\n",
    "    yh3[i] = librosa.istft(dh3[i])\n",
    "    yp3[i] = librosa.istft(dp3[i])\n",
    "    print(datetime.datetime.now()-start)\n",
    "\n",
    "# IPython.display.Audio(data=yp[0], rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=yp[1], rate=sr, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb, srb = librosa.load(librosa.ex('vibeace'), duration = 60)\n",
    "Db = librosa.stft(yb)\n",
    "rpb = np.max(np.abs(Db))\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True)\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(np.abs(Db), ref=rpb),\n",
    "                         y_axis='log', x_axis='time', ax=ax)\n",
    "IPython.display.Audio(data=yb, rate=srb, autoplay = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute separations for a few different margins and compare the results below\n",
    "# D_harmonic2, D_percussive2 = librosa.decompose.hpss(D, margin=2)\n",
    "# D_harmonic4, D_percussive4 = librosa.decompose.hpss(D, margin=4)\n",
    "# D_harmonic8, D_percussive8 = librosa.decompose.hpss(D, margin=8)\n",
    "# D_harmonic16, D_percussive16 = librosa.decompose.hpss(D, margin=16)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, sharex=True, sharey=True)\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic2), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[0])\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic4), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[1])\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic8), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[2])\n",
    "\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_harmonic16), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_harmonic2, y_percussive2 = librosa.effects.hpss(y, margin=2)\n",
    "IPython.display.Audio(data=y_harmonic2, rate=sr)\n",
    "\n",
    "y_harmonic4, y_percussive4 = librosa.effects.hpss(y, margin=4)\n",
    "IPython.display.Audio(data=y_harmonic4, rate=sr)\n",
    "\n",
    "y_harmonic8, y_percussive8 = librosa.effects.hpss(y, margin=8)\n",
    "IPython.display.Audio(data=y_harmonic8, rate=sr)\n",
    "\n",
    "y_harmonic16, y_percussive16 = librosa.effects.hpss(y, margin=16)\n",
    "IPython.display.Audio(data=y_harmonic16, rate=sr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y_h, rate=sr, autoplay = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about something more advanced?  Let's decompose a spectrogram with NMF, and then resynthesize an individual component\n",
    "D = librosa.stft(y)\n",
    "rp = np.max(np.abs(D))\n",
    "\n",
    "# Separate the magnitude and phase\n",
    "S, phase = librosa.magphase(D_harmonic)\n",
    "\n",
    "# Decompose by nmf\n",
    "components, activations = librosa.decompose.decompose(S, n_components=4, sort=True)\n",
    "# Resynthesize.  How about we isolate components?\n",
    "fig, ax = plt.subplots(nrows=len(activations), sharex=True, sharey=True)\n",
    "\n",
    "y_k = list(range(len(activations)))\n",
    "for k in range(len(activations)):\n",
    "    \n",
    "    # Reconstruct a spectrogram by the outer product of component k and its activation\n",
    "    D_k = np.multiply.outer(components[:, k], activations[k])\n",
    "\n",
    "    # invert the stft after putting the phase back in\n",
    "    y_k[k] = librosa.istft(D_k * phase)\n",
    "\n",
    "    # And playback\n",
    "    print('Component #{}'.format(k))\n",
    "\n",
    "    IPython.display.Audio(data=y_k[k], rate=sr)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D_k), ref=rp),\n",
    "                         y_axis='log', x_axis='time', ax=ax[k])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y_k[2], rate=sr, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y, rate=sr, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
